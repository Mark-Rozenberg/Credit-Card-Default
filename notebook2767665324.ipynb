{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,accuracy_score,jaccard_score,f1_score,log_loss,classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torch.nn.functional as F\ndest = '/content/drive/MyDrive/Python/Chicago-Crime/'\nBaseDat = pd.read_csv(dest + 'Chicago_Crime_Final_Data.csv')","metadata":{"id":"obx9G8u--BeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#- i will keep only the 10 most frequent types of crime for prediction -#\nKeepList = ['BATTERY','THEFT','CRIMINAL DAMAGE','ASSAULT','DECEPTIVE PRACTICE',\n            'OTHER OFFENSE','MOTOR VEHICLE THEFT','WEAPONS VIOLATION','ROBBERY','BURGLARY']\nBaseDat = BaseDat[BaseDat['primary_type'].isin(KeepList)]\nBaseDat['Location_Desc'] = BaseDat.location_description.astype(\"category\").cat.codes\nBaseDat['Type'] = BaseDat.primary_type.astype(\"category\").cat.codes\n#- this datframe will hold the classes description -#\nTypesCodes = pd.DataFrame(BaseDat.groupby('primary_type')['Type'].max())\nBaseDat = BaseDat.drop(columns=['primary_type','location_description','Date'])\nBaseDat.head(3)        ","metadata":{"id":"PEOpTZC8AAom","outputId":"d6fbb37a-1b40-45a8-b7f3-0005827b8543"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Weights = np.array(BaseDat['Type'].value_counts(normalize=True,sort=False))\nTens_Weights = torch.from_numpy(Weights).type(torch.FloatTensor)\n# print(Weights)\n# print(Tens_Weights)\nweighted_sampler = WeightedRandomSampler(weights=Tens_Weights,num_samples=len(Tens_Weights),replacement=True)","metadata":{"id":"73C_8bOIsxPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Weights)","metadata":{"id":"cUGi4aBk8P4q","outputId":"10cef07c-af49-499f-cbb3-96c0086a6553"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deep Neural Network (DNN) with PyTorch","metadata":{"id":"mWpXmWbztkP-"}},{"cell_type":"markdown","source":"### Standartization and spliting","metadata":{"id":"D0fuxOZNuCVW"}},{"cell_type":"code","source":"y = BaseDat.loc[:, BaseDat.columns == 'Type']\nX = BaseDat.drop(['Type'],axis=1)\n#- convert to arrays -#\nX = np.asarray(X)\ny = np.asarray(y)\n#- standardizing the features and spliting for train/test -#\nX = preprocessing.MinMaxScaler().fit(X).transform(X)\nprint(X.shape)\n#- split -#\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"id":"HvlLIx5suKw1","outputId":"a24db10c-adc6-447c-96b5-f72fa66bb2f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Data():\n    # Constructor\n    def __init__(self, x_tensor, y_tensor):\n        self.y = y_tensor \n        self.x = x_tensor \n    # Getter    \n    def __getitem__(self, index):\n        return (self.x[index], self.y[index])\n    # Get Length   \n    def __len__ (self):\n        return len(self.x)","metadata":{"id":"qF7x20WoJxHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.layer1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.layer2 = nn.Linear(hidden_size, num_classes)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.relu(out)\n        out = self.layer2(out)\n        return out","metadata":{"id":"XleqT3tMjvRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define The accuracy function\ndef accuracy(model, data_set):\n    _, yhat = torch.max(model(data_set.x), 1)\n    return (yhat == data_set.y).numpy().mean()","metadata":{"id":"hDl3b63rK6na"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the training function of the model\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=200):\n    LOSS = []\n    for epoch in range(epochs):\n        print('Epoch num:', epoch)\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            yhat = model(x)\n            loss = criterion(yhat, torch.max(y, 1)[1])\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            LOSS.append(loss.item())\n        print('Loss:', loss.item())","metadata":{"id":"Vjn10v2G3REF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#- prepare the tensors for input\nx_train_tensor = torch.from_numpy(X_train).type(torch.FloatTensor)\ny_train_tensor = torch.from_numpy(y_train).type(torch.LongTensor)\ndata_set = Data(x_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(dataset=data_set, batch_size=1000, sampler=weighted_sampler)","metadata":{"id":"w3wO_p-aXrA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set the parameters (1 hidden layer with 100 neurons)\ninput_size = 22\nhidden_size = 100\nnum_classes = 10\nmodel = NeuralNet(input_size, hidden_size, num_classes)\nlearning_rate = 0.0001\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"id":"zNlnmn6lLRzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train he model\nLOSS = train(data_set, model, criterion, train_loader, optimizer, epochs=200)","metadata":{"id":"F3zXt4ZVbVhB","outputId":"868abe52-4053-4d8a-93a1-30f854b36fcf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy on test Data","metadata":{"id":"wIkTiKqxkO6r"}},{"cell_type":"code","source":"x_test_tensor = torch.from_numpy(X_test).type(torch.FloatTensor)\ny_test_tensor = torch.from_numpy(y_test).type(torch.LongTensor)\npredicted = model(x_test_tensor)\n_, predicted_Class = torch.max(predicted, dim=1)","metadata":{"id":"RDF_9JhgkJDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(y_test_tensor[:2])\n# print(predicted[:2])\n# print(predicted_Class[:2])","metadata":{"id":"eXYxezEdemnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set = Data(x_test_tensor, y_test_tensor)\nAccu = accuracy(model, data_set)\nprint('Accuracy of DL Model:', Accu)\nprint(classification_report(y_test, predicted_Class))\nfig, ax = plt.subplots(figsize=(15, 8))\nax = sns.heatmap(confusion_matrix(y_test, predicted_Class), annot=True, fmt=\"d\")\nplt.xlabel('Predicted', fontsize = 15)\nplt.ylabel('Actual', fontsize = 15)\nplt.show()","metadata":{"id":"mdQqNWyGeSWU","outputId":"3b963bb8-be07-43d5-947c-a2c2fd5cf3d2"},"execution_count":null,"outputs":[]}]}